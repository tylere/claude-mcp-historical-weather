{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7752c7",
   "metadata": {},
   "source": [
    "# MCP Historical Weather Comparison\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tylere/claude-mcp-historical-weather/blob/main/demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use **Model Context Protocol (MCP)** to extend Claude's capabilities with real-time data access. We'll build a system that allows Claude to access historical weather data and compare annual weather statistics between locations.\n",
    "\n",
    "### What is MCP?\n",
    "\n",
    "Model Context Protocol (MCP) is a standard that enables AI models to securely connect with external data sources and tools. Instead of being limited to training data, models can access live information, APIs, and services.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Limitations of LLMs without external tools** - See how Claude responds to weather queries without access to real data\n",
    "2. **MCP Integration** - Connect Claude to a historical weather API\n",
    "3. **Data Visualization** - Create aesthetically pleasing charts comparing weather patterns\n",
    "4. **Interactive Analysis** - Ask Claude to analyze and compare weather data between locations\n",
    "\n",
    "### Goals\n",
    "\n",
    "By the end of this notebook, you'll have a working system that can:\n",
    "- Fetch historical weather data for locations\n",
    "- Compare annual weather statistics between cities\n",
    "- Generate visualizations and insights about weather patterns\n",
    "- Demonstrate the power of extending LLMs with external data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfc692",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "This notebook is designed to work in both Google Colab and local Jupyter environments. The following cell automatically detects if it is run within Colab installs the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0296q9lew9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in {'Google Colab' if IN_COLAB else 'local Jupyter environment'}\")\n",
    "\n",
    "# Install required packages\n",
    "if IN_COLAB:\n",
    "    # Define packages that match pyproject.toml dependencies\n",
    "    packages = [\n",
    "        \"altair>=5.5.0\",\n",
    "        \"anthropic>=0.66.0\",\n",
    "        \"ipykernel>=6.30.1\",\n",
    "        \"mcp>=1.13.1\",\n",
    "        \"numpy>=2.2.6\",\n",
    "        \"openmeteo-requests>=1.7.2\",\n",
    "        \"pandas>=2.3.2\",\n",
    "        \"requests>=2.32.5\",\n",
    "        \"requests-cache>=1.2.1\",\n",
    "        \"retry-requests>=2.0.0\",\n",
    "    ]\n",
    "    \n",
    "    print(\"Installing required packages...\")\n",
    "    for package in packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        !pip install {package}\n",
    "    \n",
    "    print(\"‚úì All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i7eh8nmjwt",
   "metadata": {},
   "source": [
    "### Python Package Imports\n",
    "\n",
    "Now let's import all the necessary packages for our weather comparison system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shi699mdg4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import getpass\n",
    "\n",
    "# Data handling and validation\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Visualization\n",
    "import altair as alt\n",
    "\n",
    "# For displaying rich notebook content\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Claude API\n",
    "import anthropic\n",
    "\n",
    "import requests_cache  # for caching API responses\n",
    "from retry_requests import retry  # for retrying API requests\n",
    "import openmeteo_requests  # for making API requests to Open-Meteo\n",
    "\n",
    "import pandas as pd  # for data manipulation\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tvr3i79qmng",
   "metadata": {},
   "source": [
    "### Anthropic API Key Setup\n",
    "\n",
    "We need to securely obtain your Anthropic API key to interact with Claude. The helper function below retrieves a user's Anthropic API key. If the API key is not stored as an environment variable or a Colab secret, it prompts the user to enter their key in a safe manner that doesn't store the key in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r9yh2vsfxv9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    try:\n",
    "        if IN_COLAB:\n",
    "            # Import package for accessing user data\n",
    "            from google.colab import userdata\n",
    "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "        else:\n",
    "            api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    except:\n",
    "        # Prompt user for their API key\n",
    "        api_key = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b39f1",
   "metadata": {},
   "source": [
    "### Verbose Output?\n",
    "\n",
    "Let's also define a flag variable for controlling how verbose the output it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_output = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575uf18qwy",
   "metadata": {},
   "source": [
    "## Motivation: Do we actually need to extend LLMs?\n",
    "\n",
    "Before diving into MCP integration, let's first see what happens when we ask Claude to compare weather data between two locations **without giving it access to any external tools or data sources**.\n",
    "\n",
    "This will demonstrate the fundamental limitation of LLMs: they can only work with information from their training data, which has a knowledge cutoff and may not include specific, current, or detailed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86148555",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_question = \"\"\"\n",
    "Please compare the annual weather statistics for the years 2000-2023\n",
    "for San Francisco, Seattle, and Austin, and Redwood City. \n",
    "\n",
    "I'd like to see:\n",
    "1. Days where the maximum temperature is between 18 and 24 degrees Celsius\n",
    "2. Days where the precipitation exceeds 10 mm\n",
    "3. Days where the sun duration exceeded 6*60*60 seconds\n",
    "4. Days where the humidity is between 30 and 60%\n",
    "\n",
    "Please provide specific data and create a comparison showing which city had more favorable weather conditions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad8ad8",
   "metadata": {},
   "source": [
    "Why **Redwood City**?\n",
    "\n",
    "The city's slogan is *\"Climate Best By Government Test\"*. According to [wikipedia](https://en.wikipedia.org/wiki/Redwood_City,_California#Slogan), this is based on a climatological survey conducted by the United States and German governments prior to World War I. So it seems like a good baseline city for comparisons in terms of climate.\n",
    "\n",
    "<a title=\"Coolcaesar, CC BY 4.0 &lt;https://creativecommons.org/licenses/by/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Redwood_City_Western_Arch.jpg\"><img alt=\"The arch at the western end of downtown Redwood City, California with the city slogan, Climate Best by Government Test.\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Redwood_City_Western_Arch.jpg/1024px-Redwood_City_Western_Arch.jpg?20250816212854\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7571b0",
   "metadata": {},
   "source": [
    "Let's ask Claude our weather question, without using any extra tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w7cevzhn4cr",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_claude_without_tools(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to Claude without any external tools or data access.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask Claude\n",
    "    \n",
    "    Returns:\n",
    "        Claude's response as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = anthropic.Anthropic(api_key=get_api_key())\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": question\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test Claude's response without external data\n",
    "print(\"ü§ñ Asking Claude about weather data WITHOUT external tools...\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Question: {weather_question}\")\n",
    "print(\"=\"*70)\n",
    "print(\"Claude's Response:\")\n",
    "print()\n",
    "\n",
    "response = ask_claude_without_tools(weather_question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51k0jp8n6wb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Key Observations:</b> The LLM model (without tools) returns some general context, but we can do better than that!\n",
    "</div>\n",
    "\n",
    "As you can see from Claude's response above, without access to external data sources, the model has several limitations:\n",
    "\n",
    "1. **No real-time data**: Claude can't access current or specific historical weather data\n",
    "2. **General knowledge only**: Responses are based on general patterns from training data\n",
    "3. **No specific metrics**: Can't provide exact precipitation amounts, temperatures, or day counts\n",
    "4. **No visualizations**: Can't create charts or graphs from actual data\n",
    "\n",
    "These gaps can be addressed by custom tools and the **Model Context Protocol (MCP)** - they can be used to bridge the gap between the model's reasoning capabilities and real-world data access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zkk6m7ulbb",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "In this section we will create some Python functions that:\n",
    "- retrieve daily data from the Open-Mateo Weather API for a list of locations\n",
    "- aggregate daily data to annual summaries\n",
    "- create a time-series chart, plotting the annual data and a trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22ce73",
   "metadata": {},
   "source": [
    "We start by defining a simple Location class that contains the latitude and longitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f95994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(BaseModel):\n",
    "    name: str\n",
    "    longitude: float\n",
    "    latitude: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cde5c4",
   "metadata": {},
   "source": [
    "## Get weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae802c",
   "metadata": {},
   "source": [
    "Next we configure access to the [Open-Meteo API](https://open-meteo.com/), including a cache and retry mechanism to avoid using the API unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "weather_variables = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"relative_humidity_2m_max\",\n",
    "    \"relative_humidity_2m_mean\",\n",
    "    \"relative_humidity_2m_min\",\n",
    "    \"rain_sum\",\n",
    "    \"precipitation_hours\",\n",
    "    \"sunshine_duration\",\n",
    "  ]\n",
    "\n",
    "# Setup an Open-Meteo API client with a cache and retry mechanism\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b83cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The Open-Meteo API offers free access for non-commercial use. If you want to use the API commercially (or just want to support the project) consider <a href=\"https://open-meteo.com/en/pricing\">purchasing an commercial use license</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5233d43",
   "metadata": {},
   "source": [
    "Next we define a function to retrieve weather data from one or more locations, returning the data as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b881f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(\n",
    "      locations: list[Location],\n",
    "      start_date: str,\n",
    "      end_date: str,\n",
    "      variables: list[str]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Get weather data for one or more locations.\n",
    "    \n",
    "    Args:\n",
    "        locations: List of Location objects\n",
    "        start_date: Start date in YYYY-MM-DD format\n",
    "        end_date: End date in YYYY-MM-DD format\n",
    "        variables: List of weather variables to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame with weather data\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_response(variables, response, location_name):\n",
    "        daily = response.Daily()\n",
    "        daily_data_dict = {\n",
    "            \"date\": pd.date_range(\n",
    "            start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "            inclusive = \"left\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # Add the variable data.\n",
    "        for i, variable in enumerate(variables):\n",
    "            daily_data_dict[variable] = daily.Variables(i).ValuesAsNumpy()\n",
    "\n",
    "        # Add a column for the location name.\n",
    "        daily_data_dict[\"location_name\"] = location_name\n",
    "\n",
    "        return pd.DataFrame(daily_data_dict)\n",
    "\n",
    "  \n",
    "    params = {\n",
    "        \"latitude\": [x.latitude for x in locations],\n",
    "        \"longitude\": [x.longitude for x in locations],\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": variables,\n",
    "    }\n",
    "\n",
    "    # Query for weather data and get one response per location.\n",
    "    responses = openmeteo.weather_api(api_url, params=params)\n",
    "\n",
    "    # Concatenate all of the responses into a single dataframe\n",
    "    daily_df_list = [parse_response(variables, response, locations[i].name) for i, response in enumerate(responses)]\n",
    "    daily_df = pd.concat(daily_df_list, axis=0)\n",
    "\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584e642",
   "metadata": {},
   "source": [
    "### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_locations = [\n",
    "  Location(\n",
    "    name='San Francisco',\n",
    "    latitude=37.7749,\n",
    "    longitude=-122.4194,\n",
    "  ),\n",
    "  Location(\n",
    "    name='Redwood City',\n",
    "    latitude=37.4848,\n",
    "    longitude=-122.2281,\n",
    "  )\n",
    "]\n",
    "\n",
    "# Test the original functionality\n",
    "daily_data = get_weather_data(\n",
    "  locations=test_locations,\n",
    "  start_date=\"2000-01-01\",\n",
    "  end_date=\"2019-12-31\",\n",
    "  variables=['temperature_2m_mean', 'temperature_2m_max', 'rain_sum', 'sunshine_duration']\n",
    ")\n",
    "daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ad0cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Sometimes the free Open-Meteo API gets overloaded and times out.\n",
    "If this happens, take it as a suggestion to stand up and stretch for a few minutes. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19105086",
   "metadata": {},
   "source": [
    "## Calculate Annual Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392a73a",
   "metadata": {},
   "source": [
    "To enable better long-term comparisons, we can write a function that calculates annual statistics of how many times a variable exceeds a minimum or maximum threshold.\n",
    "\n",
    "Examples:\n",
    "- Days that the maximum temperature exceeds 30 degrees C\n",
    "- Days that the mean temperatures is between 20 and 25 degrees C\n",
    "- Days that rain exceeds 2 mm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29650c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_annual_stats(\n",
    "    daily_data: pd.DataFrame,\n",
    "    variable: str,\n",
    "    threshold_min: float = None,\n",
    "    threshold_max: float = None\n",
    "    ) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Calculate annual statistics for the given daily data.\n",
    "  \n",
    "  Args:\n",
    "    daily_data: DataFrame containing weather data\n",
    "    variable: Name of the variable column to analyze\n",
    "    threshold_min: Optional minimum threshold (inclusive)\n",
    "    threshold_max: Optional maximum threshold (inclusive)\n",
    "  \n",
    "  Returns:\n",
    "    DataFrame with columns: year, count, location_name\n",
    "  \"\"\"\n",
    "  # Validate threshold parameters\n",
    "  if threshold_min is None and threshold_max is None:\n",
    "    raise ValueError(\"At least one of threshold_min or threshold_max must be provided\")\n",
    "  \n",
    "  # Get unique location names from the daily data\n",
    "  locations = daily_data['location_name'].unique()\n",
    "  \n",
    "  # Initialize list to store results\n",
    "  results = []\n",
    "  \n",
    "  # Process each location\n",
    "  for location in locations:\n",
    "    # Filter data for this location and make an explicit copy to avoid SettingWithCopyWarning\n",
    "    location_data = daily_data[daily_data['location_name'] == location].copy()\n",
    "    \n",
    "    # Extract year from date column\n",
    "    location_data['year'] = pd.to_datetime(location_data['date']).dt.year\n",
    "    \n",
    "    # Apply threshold filters\n",
    "    def count_days_in_range(x):\n",
    "      mask = pd.Series(True, index=x.index)  # Start with all True\n",
    "      \n",
    "      if threshold_min is not None:\n",
    "        mask = mask & (x >= threshold_min)\n",
    "      \n",
    "      if threshold_max is not None:\n",
    "        mask = mask & (x <= threshold_max)\n",
    "      \n",
    "      return mask.sum()\n",
    "    \n",
    "    yearly_counts = location_data.groupby('year')[variable].apply(count_days_in_range)\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    yearly_df = pd.DataFrame({\n",
    "      'year': yearly_counts.index,\n",
    "      'count': yearly_counts.values,\n",
    "      'location_name': location\n",
    "    })\n",
    "    \n",
    "    results.append(yearly_df)\n",
    "    \n",
    "  # Combine all results\n",
    "  return pd.concat(results, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3e12f",
   "metadata": {},
   "source": [
    "### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88416359",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_stats = calculate_annual_stats(\n",
    "    daily_data,\n",
    "    variable='temperature_2m_max',\n",
    "    threshold_min=20,\n",
    "    threshold_max=25\n",
    ")\n",
    "annual_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829f962",
   "metadata": {},
   "source": [
    "## Create a Timeseries Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393761b",
   "metadata": {},
   "source": [
    "Interpreting a long table of numbers can be pretty challenging for humans, so let's create a function for charting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annual_stats_chart(\n",
    "    annual_stats: pd.DataFrame,\n",
    "    title: str\n",
    "  ) -> alt.Chart:\n",
    "  \"\"\"\n",
    "  Create a chart showing the annual statistics.\n",
    "  \"\"\"\n",
    "  # Base chart with data points\n",
    "  base = alt.Chart(annual_stats).encode(\n",
    "    x='year:O',\n",
    "    y='count:Q',\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Create line chart\n",
    "  lines = base.mark_line()\n",
    "\n",
    "  # Add trend lines\n",
    "  trend_lines = base.transform_regression(\n",
    "    'year', 'count', \n",
    "    groupby=['location_name']\n",
    "  ).mark_line(\n",
    "    strokeDash=[5,5]\n",
    "  ).encode(\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Combine the line and trend lines\n",
    "  return (lines + trend_lines).properties(\n",
    "    title=title\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165d51f",
   "metadata": {},
   "source": [
    "### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_annual_stats_chart(\n",
    "    annual_stats,\n",
    "    title='Days with Temperature Mean between 20 and 25 degrees C'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6ede8",
   "metadata": {},
   "source": [
    "Now that we have functions to retrieve, analyze, and format weather statistics. In the following section we will expose that functionality to Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3942e",
   "metadata": {},
   "source": [
    "# MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb71e89",
   "metadata": {},
   "source": [
    "We will use the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) approach to connect Claude to the tools we built\n",
    "\n",
    "We start off by defining a Python class that acts as a MCP client. This client has the ability to:\n",
    "- Register tools\n",
    "- Execute tools\n",
    "- Process tool results\n",
    "- Chat with Claude (using the tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPClient:\n",
    "    \"\"\"A client for interacting with Claude using the Model Context Protocol (MCP).\n",
    "    \n",
    "    This class handles registering tools, executing them, and managing conversations with \n",
    "    Claude using the MCP format. It processes both text and image outputs from tools\n",
    "    and formats them appropriately for Claude's consumption.\n",
    "\n",
    "    Attributes:\n",
    "        client: The Anthropic client instance\n",
    "        tools: List of registered MCP tools\n",
    "        tool_functions: Dictionary mapping tool names to their implementation functions\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.tools = []\n",
    "        self.tool_functions = {}\n",
    "    \n",
    "    def register_tool(self, name, description, input_schema, function):\n",
    "        \"\"\"Register an MCP tool\"\"\"\n",
    "        tool = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"input_schema\": input_schema\n",
    "        }\n",
    "        self.tools.append(tool)\n",
    "        self.tool_functions[name] = function\n",
    "    \n",
    "    def execute_tool(self, tool_name, tool_input):\n",
    "        \"\"\"Execute a registered tool\"\"\"\n",
    "        if tool_name in self.tool_functions:\n",
    "            return self.tool_functions[tool_name](**tool_input)\n",
    "        else:\n",
    "            return f\"Tool {tool_name} not found\"\n",
    "    \n",
    "    def _process_mcp_tool_result(self, tool_result_json: str):\n",
    "        \"\"\"Process MCP tool result and return content for Claude\"\"\"\n",
    "        try:\n",
    "            result = json.loads(tool_result_json)\n",
    "            if \"error\" in result:\n",
    "                return [{\"type\": \"text\", \"text\": f\"Error: {result['error']}\"}]\n",
    "            \n",
    "            content = []\n",
    "            \n",
    "            # Add text content\n",
    "            if \"text\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": result[\"text\"]\n",
    "                })\n",
    "            \n",
    "            if \"location\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"location\",\n",
    "                    \"text\": f\"Location: {result['location']}\"\n",
    "                })\n",
    "\n",
    "            # Add image content \n",
    "            if \"chart_json\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"application/vnd.vegalite.v5+json\",\n",
    "                        \"data\": result[\"chart_json\"]\n",
    "                    }\n",
    "                })\n",
    "            return content\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # If not JSON, treat as plain text\n",
    "            return [{\"type\": \"text\", \"text\": tool_result_json}]\n",
    "\n",
    "    def chat_with_tools(self,\n",
    "                        user_message,\n",
    "                        model=\"claude-sonnet-4-20250514\",\n",
    "                        max_iterations=10):\n",
    "        \"\"\"Send messages and handle tool calls automatically\"\"\"\n",
    "        \n",
    "        # Initialize the messages list\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "        # Track images generated by tools throughout the conversation\n",
    "        tool_images = []\n",
    "\n",
    "        for iteration in range(max_iterations):\n",
    "            if verbose_output:\n",
    "                display(Markdown(f\"`chat_with_tools()`: Iteration {iteration + 1} --------------------------\"))\n",
    "            try:\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f\"`chat_with_tools()`: messages =\"))\n",
    "                    pprint(messages)\n",
    "                # Make request to Claude with tools\n",
    "                response = self.client.messages.create(\n",
    "                    model=model,\n",
    "                    max_tokens=4096,\n",
    "                    tools=self.tools,\n",
    "                    messages=messages\n",
    "                )\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f\"`chat_with_tools()`: response.content =\"))\n",
    "                    for block in response.content:\n",
    "                        pprint(block)\n",
    "                \n",
    "                # Add assistant's response to conversation\n",
    "                messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f'`chat_with_tools()`: {response.stop_reason = }'))\n",
    "                if response.stop_reason == \"tool_use\":\n",
    "                    # Process all tool uses via MCP\n",
    "                    tool_results = []\n",
    "                    \n",
    "                    for block in response.content:\n",
    "                        if block.type == \"tool_use\":\n",
    "\n",
    "                            mcp_result = self.execute_tool(block.name, block.input)\n",
    "                            content = self._process_mcp_tool_result(mcp_result)\n",
    "\n",
    "                            # Extract and store any images from tool results\n",
    "                            image_free_content = []\n",
    "                            for content_item in content:\n",
    "                                if content_item['type'] == 'image':\n",
    "                                    tool_images.append(content_item)\n",
    "                                else:\n",
    "                                    image_free_content.append(content_item)\n",
    "\n",
    "                            tool_results.append({\n",
    "                                \"type\": \"tool_result\",\n",
    "                                \"tool_use_id\": block.id,\n",
    "                                \"content\": image_free_content\n",
    "                            })\n",
    "                    \n",
    "                    # Add tool results to conversation\n",
    "                    messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "                    \n",
    "                    # Continue conversation loop\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    # Final response - display both text and any tool-generated images\n",
    "                    \n",
    "                    # Create a custom response object that includes tool images\n",
    "                    class ResponseWithImages:\n",
    "                        def __init__(self, original_response, tool_images):\n",
    "                            self.content = []\n",
    "                            \n",
    "                            # Add original text content\n",
    "                            for block in original_response.content:\n",
    "                                self.content.append(block)\n",
    "                            \n",
    "                            # Add tool-generated images as additional content\n",
    "                            for image in tool_images:\n",
    "                                # Convert tool image format to Claude response format\n",
    "                                image_block = type('ImageBlock', (), {\n",
    "                                    'type': 'image',\n",
    "                                    'source': type('Source', (), {\n",
    "                                        'data': image['source']['data'],\n",
    "                                        'media_type': image['source']['media_type']\n",
    "                                    })()\n",
    "                                })()\n",
    "                                self.content.append(image_block)\n",
    "                    \n",
    "                    # Return enhanced response with images\n",
    "                    return ResponseWithImages(response, tool_images)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in iteration {iteration + 1}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        print(f\"\\nReached maximum iterations ({max_iterations})\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a72c0",
   "metadata": {},
   "source": [
    "Next we define an MCP tool that can be used to comparing annual weather statistics at one or more locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_locations_mcp(\n",
    "    locations: list,\n",
    "    variable: str,\n",
    "    threshold_min: float = None,\n",
    "    threshold_max: float = None,\n",
    "    start_year: int = None,\n",
    "    end_year: int = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Compare the annual weather statistics for one or more locations.\n",
    "    \n",
    "    Args:\n",
    "        locations: List of locations to analyze and compare\n",
    "        variable: Weather variable to compare\n",
    "        threshold_min: Optional minimum threshold (inclusive)\n",
    "        threshold_max: Optional maximum threshold (inclusive)\n",
    "        start_year: Start year (default: 50 years before end_year)\n",
    "        end_year: End year (default: previous year)\n",
    "        \n",
    "    Returns:\n",
    "        JSON string containing weather comparison text and chart data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not locations or len(locations) == 0:\n",
    "            return json.dumps({\"error\": \"At least one location must be provided\"})\n",
    "        \n",
    "        # Convert dictionaries to Location objects\n",
    "        location_objects = []\n",
    "        for loc in locations:\n",
    "            if isinstance(loc, dict):\n",
    "                location_objects.append(Location(\n",
    "                    name=loc[\"name\"],\n",
    "                    latitude=loc[\"latitude\"],\n",
    "                    longitude=loc[\"longitude\"]\n",
    "                ))\n",
    "            else:\n",
    "                location_objects.append(loc)\n",
    "\n",
    "        # Set default year range if not provided\n",
    "        if end_year is None:\n",
    "            end_year = datetime.now().year - 1  # Default to previous year\n",
    "        if start_year is None:\n",
    "            start_year = end_year - 50  # Default to 50 years before end_year\n",
    "        \n",
    "        # Fetch weather data for all locations\n",
    "        weather_data = get_weather_data(\n",
    "            locations=location_objects,\n",
    "            start_date=f\"{start_year}-01-01\",\n",
    "            end_date=f\"{end_year}-12-31\",\n",
    "            variables=[variable]\n",
    "        )\n",
    "                \n",
    "        # Calculate annual statistics if thresholds were provided\n",
    "        if threshold_min is not None or threshold_max is not None:\n",
    "            annual_stats = calculate_annual_stats(\n",
    "                daily_data=weather_data,\n",
    "                variable=variable,\n",
    "                threshold_min=threshold_min,\n",
    "                threshold_max=threshold_max\n",
    "            )\n",
    "            \n",
    "            # Create chart\n",
    "            threshold_desc = \"\"\n",
    "            if threshold_min is not None and threshold_max is not None:\n",
    "                threshold_desc = f\"Days of {variable} between {threshold_min} and {threshold_max}\"\n",
    "            elif threshold_min is not None:\n",
    "                threshold_desc = f\"Days of {variable} above {threshold_min}\"\n",
    "            elif threshold_max is not None:\n",
    "                threshold_desc = f\"Days of {variable} below {threshold_max}\"\n",
    "            \n",
    "            chart = create_annual_stats_chart(annual_stats, threshold_desc)\n",
    "        else:\n",
    "            # Just show raw data comparison without thresholds\n",
    "            annual_stats = None\n",
    "            chart = None\n",
    "        \n",
    "        # Generate comparison text for all locations\n",
    "        comparison_text = f\"üåç Location Analysis: {', '.join([loc.name for loc in location_objects])}\\n\\n\"\n",
    "        comparison_text += f\"üìä {variable.replace('_', ' ').title()} Analysis:\\n\\n\"\n",
    "        \n",
    "        # Statistics for each location\n",
    "        location_stats = []\n",
    "        for loc in location_objects:\n",
    "            loc_data = weather_data[weather_data['location_name'] == loc.name]\n",
    "            if not loc_data.empty:\n",
    "                avg_val = loc_data[variable].mean()\n",
    "                min_val = loc_data[variable].min()\n",
    "                max_val = loc_data[variable].max()\n",
    "                \n",
    "                location_stats.append({\n",
    "                    'name': loc.name,\n",
    "                    'avg': avg_val,\n",
    "                    'min': min_val,\n",
    "                    'max': max_val,\n",
    "                    'coordinates': f\"{loc.latitude}, {loc.longitude}\"\n",
    "                })\n",
    "                \n",
    "                comparison_text += f\"üèôÔ∏è **{loc.name}**\\n\"\n",
    "                comparison_text += f\"‚Ä¢ Average: {avg_val:.1f}\\n\"\n",
    "                comparison_text += f\"‚Ä¢ Range: {min_val:.1f} to {max_val:.1f}\\n\" \n",
    "                comparison_text += f\"‚Ä¢ Coordinates: {loc.latitude}, {loc.longitude}\\n\\n\"\n",
    "\n",
    "        # Add threshold-based analysis if applicable\n",
    "        if annual_stats is not None:\n",
    "            comparison_text += \"üéØ **Threshold Analysis:**\\n\"\n",
    "            \n",
    "            # Calculate average days per location\n",
    "            for loc in location_objects:\n",
    "                loc_stats = annual_stats[annual_stats['location_name'] == loc.name]\n",
    "                if not loc_stats.empty:\n",
    "                    avg_days = loc_stats['count'].mean()\n",
    "                    comparison_text += f\"‚Ä¢ {loc.name}: {avg_days:.0f} days per year on average\\n\"\n",
    "            \n",
    "            comparison_text += f\"‚Ä¢ Criteria: {threshold_desc}\\n\\n\"\n",
    "        \n",
    "        # Add summary comparison if more than one location\n",
    "        if len(location_objects) > 1:\n",
    "            comparison_text += \"üèÜ **Summary:**\\n\"\n",
    "            \n",
    "            # Find best and worst for average values\n",
    "            if location_stats:\n",
    "                best_avg = max(location_stats, key=lambda x: x['avg'])\n",
    "                worst_avg = min(location_stats, key=lambda x: x['avg'])\n",
    "                \n",
    "                comparison_text += f\"‚Ä¢ Highest average {variable.replace('_', ' ')}: {best_avg['name']} ({best_avg['avg']:.1f})\\n\"\n",
    "                comparison_text += f\"‚Ä¢ Lowest average {variable.replace('_', ' ')}: {worst_avg['name']} ({worst_avg['avg']:.1f})\\n\"\n",
    "                \n",
    "                # Add threshold analysis summary if available\n",
    "                if annual_stats is not None:\n",
    "                    threshold_stats = []\n",
    "                    for loc in location_objects:\n",
    "                        loc_stats = annual_stats[annual_stats['location_name'] == loc.name]\n",
    "                        if not loc_stats.empty:\n",
    "                            avg_days = loc_stats['count'].mean()\n",
    "                            threshold_stats.append({'name': loc.name, 'avg_days': avg_days})\n",
    "                    \n",
    "                    if threshold_stats:\n",
    "                        best_threshold = max(threshold_stats, key=lambda x: x['avg_days'])\n",
    "                        comparison_text += f\"‚Ä¢ Most days meeting criteria: {best_threshold['name']} ({best_threshold['avg_days']:.0f} days/year)\\n\"\n",
    "\n",
    "        result = {\"text\": comparison_text}\n",
    "        if chart:\n",
    "            result[\"chart_json\"] = chart.to_dict()\n",
    "            \n",
    "        return json.dumps(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Location analysis failed: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f3aa2",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91c32b",
   "metadata": {},
   "source": [
    "Start by creating an instance of the MCP client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client = MCPClient(get_api_key())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d8d8a",
   "metadata": {},
   "source": [
    "Next, register our tool with the MCP client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b72ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client.register_tool(\n",
    "    name=\"compare_locations_mcp\",\n",
    "    description=\"Analyze and compare annual weather statistics for one or more cities with optional threshold analysis and visualization.\",\n",
    "    input_schema={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"locations\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"List of locations to analyze and compare\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"latitude\": {\"type\": \"number\"},\n",
    "                            \"longitude\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"name\", \"latitude\", \"longitude\"]\n",
    "                    },\n",
    "                    \"minItems\": 1\n",
    "                },\n",
    "                \"variable\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Weather variable to compare\",\n",
    "                    \"enum\": weather_variables,\n",
    "                },\n",
    "                \"threshold_min\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Optional minimum threshold for counting days (inclusive)\"\n",
    "                },\n",
    "                \"threshold_max\": {\n",
    "                    \"type\": \"number\", \n",
    "                    \"description\": \"Optional maximum threshold for counting days (inclusive)\"\n",
    "                },\n",
    "                \"start_year\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Start year (default: 50 years before end_year)\"\n",
    "                },\n",
    "                \"end_year\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"End year (default: previous year)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"locations\"]\n",
    "        },\n",
    "    function=compare_locations_mcp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e559d",
   "metadata": {},
   "source": [
    "We can verify that the MCP tool is configured properly, by executing the tool directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_results_str = mcp_client.execute_tool(\n",
    "  tool_name=\"compare_locations_mcp\",\n",
    "  tool_input={\n",
    "    \"locations\": [\n",
    "        {\n",
    "            \"name\": \"San Francisco\",\n",
    "            \"latitude\": 37.7749,\n",
    "            \"longitude\": -122.4194\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Seattle\",\n",
    "            \"latitude\": 47.6062,\n",
    "            \"longitude\": -122.3321\n",
    "        }\n",
    "    ],\n",
    "    \"variable\": \"temperature_2m_max\",\n",
    "    \"threshold_min\": 18,\n",
    "    \"threshold_max\": 24,\n",
    "    \"start_year\": 2000,\n",
    "    \"end_year\": 2019\n",
    "})\n",
    "\n",
    "tool_results = json.loads(tool_results_str)\n",
    "\n",
    "# Display the tool results\n",
    "display(Markdown(tool_results['text']))\n",
    "if 'chart_json' in tool_results:\n",
    "  display(alt.Chart.from_dict(tool_results['chart_json']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc5944",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c297ccc",
   "metadata": {},
   "source": [
    "There is one more helper function that we need to create... it converts the MCP Client response data (provided by Claude) into representations that the Jupyter notebook can display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0642b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_claude_response(response):\n",
    "    \"\"\"Display Claude response with both text and images\"\"\"    \n",
    "    if response:\n",
    "        for content in response.content:\n",
    "            if content.type == \"text\":\n",
    "                display(Markdown(content.text))\n",
    "            elif content.type == \"image\":\n",
    "                if content.source.media_type == \"application/vnd.vegalite.v5+json\":\n",
    "                    # Recreate the chart from JSON dictionary\n",
    "                    altair_chart = alt.Chart.from_dict(content.source.data)\n",
    "                    display(altair_chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0aca21",
   "metadata": {},
   "source": [
    "# Querying with the MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0827776",
   "metadata": {},
   "source": [
    "Let's review the weather question we tried asking earlier (without using tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987676de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e24f60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Tip:</b> Update this question ask for locations that are relevant to you!<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce350ea6",
   "metadata": {},
   "source": [
    "Let's ask Claude the question again, this time using the tool we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mcp_client.chat_with_tools(weather_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b25830",
   "metadata": {},
   "source": [
    "This time the result is far more detailed, and includes time series charts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aab7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_claude_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6111a",
   "metadata": {},
   "source": [
    "# Where to next?\n",
    "\n",
    "There are all kinds of directions that you could go next.  Here are a few ideas:\n",
    " \n",
    "- Implement additional weather statistics / climate indices. For inspiration, see the [ETCCDI Climate Change Indices](https://etccdi.pacificclimate.org/list_27_indices.shtml) compiled by [CLIVAR](https://www.clivar.org/).\n",
    "- Add functionality to analyze weather forecast data. The [Open-Meteo Weather Forecast API](https://open-meteo.com/en/docs) (rather than the Historical Weather API used in this notebook) provides forecasts up to 16 days in the future.\n",
    "- Use this same approach to provide Claude access to other large datasets, such as genomic sequence data or satellite imagery!\n",
    "\n",
    "Happy data exploring!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
