{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7752c7",
   "metadata": {},
   "source": [
    "# MCP Historical Weather Comparison\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tylere/claude-mcp-historical-weather/blob/main/demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Imagine asking an AI assistant**: *\"Which city had more pleasant weather last year - Portland or Phoenix? Show me temperature patterns, rainfall data, and create visualizations comparing their climates.\"*\n",
    "\n",
    "Most AI systems today would give you general knowledge about these cities' typical weather patterns, perhaps mentioning that Phoenix is hot and dry while Portland is mild and rainy. But they can't access specific historical data, calculate exact statistics, or create custom visualizations from real weather records.\n",
    "\n",
    "**This is the fundamental limitation we're solving today.**\n",
    "\n",
    "### The Problem: AI's Knowledge Boundaries\n",
    "\n",
    "Large Language Models (LLMs) like Claude are trained on vast amounts of text data - typically 10-100 terabytes after processing. They excel at understanding language, reasoning about concepts, and providing general knowledge. However, they face two critical limitations:\n",
    "\n",
    "1. **Knowledge Cutoff**: They can't access information beyond their training date or real-time data\n",
    "2. **Specific Data Analysis**: They struggle with custom analysis of specialized datasets that weren't in their training\n",
    "\n",
    "When you ask Claude about weather patterns between specific cities for particular years, it can only provide general climatic knowledge - not the precise, data-driven analysis you actually need.\n",
    "\n",
    "### The Solution: Expanding AI's Reach\n",
    "\n",
    "**Model Context Protocol (MCP)** bridges this gap by giving AI systems secure access to external data sources and tools. Think of it as providing AI with a telescope to see beyond its training horizon, or giving it specialized instruments to perform precise measurements.\n",
    "\n",
    "Instead of being limited to static knowledge, MCP-enabled AI can:\n",
    "- **Access live data** from APIs and databases\n",
    "- **Perform custom calculations** on specific datasets  \n",
    "- **Generate visualizations** from real-world information\n",
    "- **Provide current, precise answers** to data-driven questions\n",
    "\n",
    "### The Scale of Opportunity\n",
    "\n",
    "Consider the vast landscape of specialized data that exists beyond typical AI training:\n",
    "\n",
    "Modern LLMs are trained on 10-100 TB of carefully curated text data. But domain-specific datasets dwarf this scale, containing rich information that could revolutionize how we interact with data:\n",
    "\n",
    "| Dataset | Description | Size (terabytes) |\n",
    "| ---  | --- | --- |\n",
    "| [Open-Meteo Weather](https://open-meteo.com/en/docs/historical-weather-api) | Historical weather data back to 1940 | 90 |\n",
    "| [Landsat Collection 2](https://www.usgs.gov/landsat-missions/landsat-commercial-cloud-data-access) | 5+ decades of satellite imagery | 9,000 |\n",
    "| [Sequence Read Archive (SRA)](https://www.ncbi.nlm.nih.gov/sra/docs/) | Global DNA and RNA sequencing data | 36,000 |\n",
    "\n",
    "These massive, specialized datasets are typically locked behind complex APIs and technical barriers. MCP democratizes access by allowing AI to serve as an intelligent interface to this information.\n",
    "\n",
    "### What You'll Build Today\n",
    "\n",
    "This notebook demonstrates MCP integration using historical weather data as our example domain. You'll create a system where Claude can:\n",
    "\n",
    "- **Query real weather data** spanning decades for any global location\n",
    "- **Calculate custom climate statistics** (temperature ranges, precipitation patterns, sunshine duration)  \n",
    "- **Generate beautiful visualizations** comparing weather patterns between cities\n",
    "- **Provide data-driven insights** about climate trends and patterns\n",
    "\n",
    "By the end, you'll have transformed Claude from a knowledge-limited chatbot into a powerful weather analysis assistant with access to 80+ years of global climate data.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "This tutorial will teach you to:\n",
    "\n",
    "1. **Understand MCP's Value**: See exactly what AI can accomplish when connected to real-world data\n",
    "2. **Implement MCP Integration**: Build the technical bridge between Claude and external APIs\n",
    "3. **Design Data Analysis Tools**: Create functions that transform raw data into insights\n",
    "4. **Enable Interactive Analysis**: Let users ask natural language questions about complex datasets\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Weather data is universally relatable - everyone has opinions about climate and can immediately understand the value of precise weather comparisons. But the same MCP principles apply to any domain:\n",
    "\n",
    "- **Scientific Research**: Connect AI to genomic databases, astronomical catalogs, or experimental datasets\n",
    "- **Business Intelligence**: Link AI to sales data, market research, or customer analytics  \n",
    "- **Environmental Monitoring**: Access sensor networks, satellite imagery, or ecological databases\n",
    "- **Healthcare**: Query medical databases, research papers, or treatment outcomes\n",
    "\n",
    "This weather demo serves as your blueprint for building AI systems that can intelligently interface with any specialized dataset.\n",
    "\n",
    "**Ready to give AI superpowers? Let's begin.** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfc692",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This section will get your environment ready for MCP integration. We'll handle both Google Colab and local Jupyter setups automatically.\n",
    "\n",
    "### Colab Setup (if needed)\n",
    "\n",
    "The following cell automatically detects your environment and installs the necessary dependencies for both Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0296q9lew9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in {'Google Colab' if IN_COLAB else 'local Jupyter environment'}\")\n",
    "\n",
    "# Install required packages\n",
    "if IN_COLAB:\n",
    "    # Define packages that match pyproject.toml dependencies\n",
    "    packages = [\n",
    "        \"altair>=5.5.0\",\n",
    "        \"anthropic>=0.66.0\",\n",
    "        \"ipykernel>=6.30.1\",\n",
    "        \"mcp>=1.13.1\",\n",
    "        \"numpy>=2.2.6\",\n",
    "        \"openmeteo-requests>=1.7.2\",\n",
    "        \"pandas>=2.3.2\",\n",
    "        \"requests>=2.32.5\",\n",
    "        \"requests-cache>=1.2.1\",\n",
    "        \"retry-requests>=2.0.0\",\n",
    "    ]\n",
    "    \n",
    "    print(\"Installing required packages...\")\n",
    "    for package in packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        !pip install {package}\n",
    "    \n",
    "    print(\"✓ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i7eh8nmjwt",
   "metadata": {},
   "source": [
    "### Python Package Imports\n",
    "\n",
    "Now let's import all the necessary packages for our weather comparison system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shi699mdg4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import getpass\n",
    "\n",
    "# Data handling and validation\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Visualization\n",
    "import altair as alt\n",
    "\n",
    "# For displaying rich notebook content\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Claude API\n",
    "import anthropic\n",
    "\n",
    "import requests_cache  # for caching API responses\n",
    "from retry_requests import retry  # for retrying API requests\n",
    "import openmeteo_requests  # for making API requests to Open-Meteo\n",
    "\n",
    "import pandas as pd  # for data manipulation\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tvr3i79qmng",
   "metadata": {},
   "source": [
    "### Anthropic API Key Setup\n",
    "\n",
    "To interact with Claude, we need your Anthropic API key. The function below securely retrieves it using the safest available method:\n",
    "\n",
    "1. **Environment variable** (`ANTHROPIC_API_KEY`)\n",
    "2. **Colab secrets** (if in Google Colab)  \n",
    "3. **Secure input prompt** (hidden, not stored in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r9yh2vsfxv9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    try:\n",
    "        if IN_COLAB:\n",
    "            # Import package for accessing user data\n",
    "            from google.colab import userdata\n",
    "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "        else:\n",
    "            api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    except:\n",
    "        # Prompt user for their API key\n",
    "        api_key = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b39f1",
   "metadata": {},
   "source": [
    "### Verbose Output Control\n",
    "\n",
    "Set this flag to control debugging information during MCP tool execution. Keep it `False` for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_output = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575uf18qwy",
   "metadata": {},
   "source": [
    "## Motivation: Why Do We Need to Extend LLMs?\n",
    "\n",
    "Let's start with an experiment. We'll ask Claude to analyze weather data **without giving it access to any external tools or data sources**.\n",
    "\n",
    "This demonstration will reveal the fundamental limitation that MCP solves: LLMs can only work with information from their training data, which has knowledge cutoffs and lacks access to specific, current datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86148555",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_question = \"\"\"\n",
    "Please compare the annual weather statistics for the years 2000-2023\n",
    "for San Francisco, Seattle, and Austin, and Redwood City. \n",
    "\n",
    "I'd like to see:\n",
    "1. Days where the maximum temperature is between 18 and 24 degrees Celsius\n",
    "2. Days where the precipitation exceeds 10 mm\n",
    "3. Days where the humidity is between 30 and 60%\n",
    "\n",
    "Please provide specific data and create a comparison showing which city had more favorable weather conditions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad8ad8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Why Redwood City?\n",
    "\n",
    "The city's slogan is *\"Climate Best By Government Test\"*. According to [wikipedia](https://en.wikipedia.org/wiki/Redwood_City,_California#Slogan), this is based on a climatological survey conducted by the United States and German governments prior to World War I. So it seems like a good baseline city for comparisons in terms of climate.\n",
    "\n",
    "<a title=\"Coolcaesar, CC BY 4.0 &lt;https://creativecommons.org/licenses/by/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Redwood_City_Western_Arch.jpg\"><img alt=\"The arch at the western end of downtown Redwood City, California with the city slogan, Climate Best by Government Test.\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Redwood_City_Western_Arch.jpg/1024px-Redwood_City_Western_Arch.jpg?20250816212854\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7571b0",
   "metadata": {},
   "source": [
    "Let's ask Claude our weather question, without using any extra tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w7cevzhn4cr",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_claude_without_tools(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to Claude without any external tools or data access.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask Claude\n",
    "    \n",
    "    Returns:\n",
    "        Claude's response as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = anthropic.Anthropic(api_key=get_api_key())\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": question\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test Claude's response without external data\n",
    "print(\"🤖 Asking Claude about weather data WITHOUT external tools...\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Question: {weather_question}\")\n",
    "print(\"=\"*70)\n",
    "print(\"Claude's Response:\")\n",
    "print()\n",
    "\n",
    "response = ask_claude_without_tools(weather_question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51k0jp8n6wb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The LLM model (without tools) returns some general context, but we can do better than that!\n",
    "</div>\n",
    "\n",
    "As you can see from Claude's response above, without access to external data sources, the model has several limitations:\n",
    "\n",
    "1. **No real-time data**: Claude can't access current or specific historical weather data\n",
    "2. **General knowledge only**: Responses are based on general patterns from training data\n",
    "3. **No specific metrics**: Can't provide exact precipitation amounts, temperatures, or day counts\n",
    "4. **No visualizations**: Can't create charts or graphs from actual data\n",
    "\n",
    "These gaps can be addressed by custom tools and the **Model Context Protocol (MCP)** - they can be used to bridge the gap between the model's reasoning capabilities and real-world data access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zkk6m7ulbb",
   "metadata": {},
   "source": [
    "## Analysis & Data Processing\n",
    "\n",
    "In this section, we'll create the core Python functions that power our weather analysis system:\n",
    "\n",
    "- **Retrieve** daily weather data from the Open-Meteo API for multiple locations\n",
    "- **Aggregate** daily data into meaningful annual statistics\n",
    "- **Visualize** trends with interactive time-series charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22ce73",
   "metadata": {},
   "source": [
    "### Location Data Model\n",
    "\n",
    "We start by defining a simple `Location` class using Pydantic for data validation. This ensures our coordinates are properly formatted for the weather API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f95994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(BaseModel):\n",
    "    name: str\n",
    "    longitude: float\n",
    "    latitude: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cde5c4",
   "metadata": {},
   "source": [
    "## Weather Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae802c",
   "metadata": {},
   "source": [
    "Next we'll configure access to the [Open-Meteo Historical Weather API](https://open-meteo.com/), including intelligent caching and retry mechanisms to avoid unnecessary API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "weather_variables = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"relative_humidity_2m_max\",\n",
    "    \"relative_humidity_2m_mean\",\n",
    "    \"relative_humidity_2m_min\",\n",
    "    \"rain_sum\",\n",
    "    \"precipitation_hours\",\n",
    "    \"sunshine_duration\",\n",
    "  ]\n",
    "\n",
    "# Setup an Open-Meteo API client with a cache and retry mechanism\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b83cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The Open-Meteo API offers free access for non-commercial use. If you want to use the API commercially (or just want to support the project) consider <a href=\"https://open-meteo.com/en/pricing\">purchasing an commercial use license</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5233d43",
   "metadata": {},
   "source": [
    "Next we'll define a function to retrieve weather data from one or more locations, returning the data as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b881f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(\n",
    "      locations: list[Location],\n",
    "      start_date: str,\n",
    "      end_date: str,\n",
    "      variables: list[str]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Get weather data for one or more locations.\n",
    "    \n",
    "    Args:\n",
    "        locations: List of Location objects\n",
    "        start_date: Start date in YYYY-MM-DD format\n",
    "        end_date: End date in YYYY-MM-DD format\n",
    "        variables: List of weather variables to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame with weather data\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_response(variables, response, location_name):\n",
    "        daily = response.Daily()\n",
    "        daily_data_dict = {\n",
    "            \"date\": pd.date_range(\n",
    "            start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "            inclusive = \"left\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # Add the variable data.\n",
    "        for i, variable in enumerate(variables):\n",
    "            daily_data_dict[variable] = daily.Variables(i).ValuesAsNumpy()\n",
    "\n",
    "        # Add a column for the location name.\n",
    "        daily_data_dict[\"location_name\"] = location_name\n",
    "\n",
    "        return pd.DataFrame(daily_data_dict)\n",
    "\n",
    "  \n",
    "    params = {\n",
    "        \"latitude\": [x.latitude for x in locations],\n",
    "        \"longitude\": [x.longitude for x in locations],\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": variables,\n",
    "    }\n",
    "\n",
    "    # Query for weather data and get one response per location.\n",
    "    responses = openmeteo.weather_api(api_url, params=params)\n",
    "\n",
    "    # Concatenate all of the responses into a single dataframe\n",
    "    daily_df_list = [parse_response(variables, response, locations[i].name) for i, response in enumerate(responses)]\n",
    "    daily_df = pd.concat(daily_df_list, axis=0)\n",
    "\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584e642",
   "metadata": {},
   "source": [
    "### 🧪 **Try It Out**\n",
    "\n",
    "Let's test our function with real data from two Bay Area cities to see the weather data retrieval in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_locations = [\n",
    "  Location(\n",
    "    name='San Francisco',\n",
    "    latitude=37.7749,\n",
    "    longitude=-122.4194,\n",
    "  ),\n",
    "  Location(\n",
    "    name='Redwood City',\n",
    "    latitude=37.4848,\n",
    "    longitude=-122.2281,\n",
    "  )\n",
    "]\n",
    "\n",
    "# Test the original functionality\n",
    "daily_data = get_weather_data(\n",
    "  locations=test_locations,\n",
    "  start_date=\"2000-01-01\",\n",
    "  end_date=\"2019-12-31\",\n",
    "  variables=['temperature_2m_mean', 'temperature_2m_max', 'rain_sum', 'sunshine_duration']\n",
    ")\n",
    "daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ad0cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Sometimes the free Open-Meteo API gets overloaded and times out.\n",
    "If this happens, take it as a suggestion to stand up and stretch for a few minutes. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19105086",
   "metadata": {},
   "source": [
    "## Calculate Annual Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392a73a",
   "metadata": {},
   "source": [
    "To enable better long-term comparisons, we can write a function that calculates annual statistics of how many times a variable exceeds a minimum or maximum threshold.\n",
    "\n",
    "Examples:\n",
    "- Days that the maximum temperature exceeds 30 degrees C\n",
    "- Days that the mean temperatures is between 20 and 25 degrees C\n",
    "- Days that rain exceeds 2 mm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29650c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_annual_stats(\n",
    "    daily_data: pd.DataFrame,\n",
    "    variable: str,\n",
    "    threshold_min: float = None,\n",
    "    threshold_max: float = None\n",
    "    ) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Calculate annual statistics for the given daily data.\n",
    "  \n",
    "  Args:\n",
    "    daily_data: DataFrame containing weather data\n",
    "    variable: Name of the variable column to analyze\n",
    "    threshold_min: Optional minimum threshold (inclusive)\n",
    "    threshold_max: Optional maximum threshold (inclusive)\n",
    "  \n",
    "  Returns:\n",
    "    DataFrame with columns: year, count, location_name\n",
    "  \"\"\"\n",
    "  # Validate threshold parameters\n",
    "  if threshold_min is None and threshold_max is None:\n",
    "    raise ValueError(\"At least one of threshold_min or threshold_max must be provided\")\n",
    "  \n",
    "  # Get unique location names from the daily data\n",
    "  locations = daily_data['location_name'].unique()\n",
    "  \n",
    "  # Initialize list to store results\n",
    "  results = []\n",
    "  \n",
    "  # Process each location\n",
    "  for location in locations:\n",
    "    # Filter data for this location and make an explicit copy to avoid SettingWithCopyWarning\n",
    "    location_data = daily_data[daily_data['location_name'] == location].copy()\n",
    "    \n",
    "    # Extract year from date column\n",
    "    location_data['year'] = pd.to_datetime(location_data['date']).dt.year\n",
    "    \n",
    "    # Apply threshold filters\n",
    "    def count_days_in_range(x):\n",
    "      mask = pd.Series(True, index=x.index)  # Start with all True\n",
    "      \n",
    "      if threshold_min is not None:\n",
    "        mask = mask & (x >= threshold_min)\n",
    "      \n",
    "      if threshold_max is not None:\n",
    "        mask = mask & (x <= threshold_max)\n",
    "      \n",
    "      return mask.sum()\n",
    "    \n",
    "    yearly_counts = location_data.groupby('year')[variable].apply(count_days_in_range)\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    yearly_df = pd.DataFrame({\n",
    "      'year': yearly_counts.index,\n",
    "      'count': yearly_counts.values,\n",
    "      'location_name': location\n",
    "    })\n",
    "    \n",
    "    results.append(yearly_df)\n",
    "    \n",
    "  # Combine all results\n",
    "  return pd.concat(results, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3e12f",
   "metadata": {},
   "source": [
    "### 🧪 **Try It Out**\n",
    "\n",
    "Let's test our annual statistics function with the weather data we just retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88416359",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_stats = calculate_annual_stats(\n",
    "    daily_data,\n",
    "    variable='temperature_2m_max',\n",
    "    threshold_min=20,\n",
    "    threshold_max=25\n",
    ")\n",
    "annual_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829f962",
   "metadata": {},
   "source": [
    "## Time-Series Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393761b",
   "metadata": {},
   "source": [
    "Interpreting a long table of numbers can be pretty challenging for humans, so let's create a function for charting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annual_stats_chart(\n",
    "    annual_stats: pd.DataFrame,\n",
    "    title: str\n",
    "  ) -> alt.Chart:\n",
    "  \"\"\"\n",
    "  Create a chart showing the annual statistics.\n",
    "  \"\"\"\n",
    "  # Base chart with data points\n",
    "  base = alt.Chart(annual_stats).encode(\n",
    "    x='year:O',\n",
    "    y='count:Q',\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Create line chart\n",
    "  lines = base.mark_line()\n",
    "\n",
    "  # Add trend lines\n",
    "  trend_lines = base.transform_regression(\n",
    "    'year', 'count', \n",
    "    groupby=['location_name']\n",
    "  ).mark_line(\n",
    "    strokeDash=[5,5]\n",
    "  ).encode(\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Combine the line and trend lines\n",
    "  return (lines + trend_lines).properties(\n",
    "    title=title\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165d51f",
   "metadata": {},
   "source": [
    "### 🧪 **Try It Out**\n",
    "\n",
    "Let's create an interactive chart from our annual statistics to visualize the trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_annual_stats_chart(\n",
    "    annual_stats,\n",
    "    title='Days with Temperature Mean between 20 and 25 degrees C'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6ede8",
   "metadata": {},
   "source": [
    "Now that we have functions to retrieve, analyze, and format weather statistics. In the following section we will expose that functionality to Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3942e",
   "metadata": {},
   "source": [
    "# Model Context Protocol (MCP) Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb71e89",
   "metadata": {},
   "source": [
    "Now we'll connect our weather analysis functions to Claude using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). \n",
    "\n",
    "We'll build an MCP client that can:\n",
    "- **Register tools** with Claude\n",
    "- **Execute functions** when Claude needs data\n",
    "- **Process results** and format them for display\n",
    "- **Manage conversations** with full tool integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPClient:\n",
    "    \"\"\"A client for interacting with Claude using the Model Context Protocol (MCP).\n",
    "    \n",
    "    This class handles registering tools, executing them, and managing conversations with \n",
    "    Claude using the MCP format. It processes both text and image outputs from tools\n",
    "    and formats them appropriately for Claude's consumption.\n",
    "\n",
    "    Attributes:\n",
    "        client: The Anthropic client instance\n",
    "        tools: List of registered MCP tools\n",
    "        tool_functions: Dictionary mapping tool names to their implementation functions\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.tools = []\n",
    "        self.tool_functions = {}\n",
    "    \n",
    "    def register_tool(self, name, description, input_schema, function):\n",
    "        \"\"\"Register an MCP tool\"\"\"\n",
    "        tool = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"input_schema\": input_schema\n",
    "        }\n",
    "        self.tools.append(tool)\n",
    "        self.tool_functions[name] = function\n",
    "    \n",
    "    def execute_tool(self, tool_name, tool_input):\n",
    "        \"\"\"Execute a registered tool\"\"\"\n",
    "        if tool_name in self.tool_functions:\n",
    "            return self.tool_functions[tool_name](**tool_input)\n",
    "        else:\n",
    "            return f\"Tool {tool_name} not found\"\n",
    "    \n",
    "    def _process_mcp_tool_result(self, tool_result_json: str):\n",
    "        \"\"\"Process MCP tool result and return content for Claude\"\"\"\n",
    "        try:\n",
    "            result = json.loads(tool_result_json)\n",
    "            if \"error\" in result:\n",
    "                return [{\"type\": \"text\", \"text\": f\"Error: {result['error']}\"}]\n",
    "            \n",
    "            content = []\n",
    "            \n",
    "            # Add text content\n",
    "            if \"text\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": result[\"text\"]\n",
    "                })\n",
    "            \n",
    "            if \"location\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"location\",\n",
    "                    \"text\": f\"Location: {result['location']}\"\n",
    "                })\n",
    "\n",
    "            # Add image content \n",
    "            if \"chart_json\" in result:\n",
    "                content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"application/vnd.vegalite.v5+json\",\n",
    "                        \"data\": result[\"chart_json\"]\n",
    "                    }\n",
    "                })\n",
    "            return content\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # If not JSON, treat as plain text\n",
    "            return [{\"type\": \"text\", \"text\": tool_result_json}]\n",
    "\n",
    "    def chat_with_tools(self,\n",
    "                        user_message,\n",
    "                        model=\"claude-sonnet-4-20250514\",\n",
    "                        max_iterations=10):\n",
    "        \"\"\"Send messages and handle tool calls automatically\"\"\"\n",
    "        \n",
    "        # Initialize the messages list\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "        # Track images generated by tools throughout the conversation\n",
    "        tool_images = []\n",
    "\n",
    "        for iteration in range(max_iterations):\n",
    "            if verbose_output:\n",
    "                display(Markdown(f\"`chat_with_tools()`: Iteration {iteration + 1} --------------------------\"))\n",
    "            try:\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f\"`chat_with_tools()`: messages =\"))\n",
    "                    pprint(messages)\n",
    "                # Make request to Claude with tools\n",
    "                response = self.client.messages.create(\n",
    "                    model=model,\n",
    "                    max_tokens=4096,\n",
    "                    tools=self.tools,\n",
    "                    messages=messages\n",
    "                )\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f\"`chat_with_tools()`: response.content =\"))\n",
    "                    for block in response.content:\n",
    "                        pprint(block)\n",
    "                \n",
    "                # Add assistant's response to conversation\n",
    "                messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "                if verbose_output:\n",
    "                    display(Markdown(f'`chat_with_tools()`: {response.stop_reason = }'))\n",
    "                if response.stop_reason == \"tool_use\":\n",
    "                    # Process all tool uses via MCP\n",
    "                    tool_results = []\n",
    "                    \n",
    "                    for block in response.content:\n",
    "                        if block.type == \"tool_use\":\n",
    "\n",
    "                            mcp_result = self.execute_tool(block.name, block.input)\n",
    "                            content = self._process_mcp_tool_result(mcp_result)\n",
    "\n",
    "                            # Extract and store any images from tool results\n",
    "                            image_free_content = []\n",
    "                            for content_item in content:\n",
    "                                if content_item['type'] == 'image':\n",
    "                                    tool_images.append(content_item)\n",
    "                                else:\n",
    "                                    image_free_content.append(content_item)\n",
    "\n",
    "                            tool_results.append({\n",
    "                                \"type\": \"tool_result\",\n",
    "                                \"tool_use_id\": block.id,\n",
    "                                \"content\": image_free_content\n",
    "                            })\n",
    "                    \n",
    "                    # Add tool results to conversation\n",
    "                    messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "                    \n",
    "                    # Continue conversation loop\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    # Final response - display both text and any tool-generated images\n",
    "                    \n",
    "                    # Create a custom response object that includes tool images\n",
    "                    class ResponseWithImages:\n",
    "                        def __init__(self, original_response, tool_images):\n",
    "                            self.content = []\n",
    "                            \n",
    "                            # Add original text content\n",
    "                            for block in original_response.content:\n",
    "                                self.content.append(block)\n",
    "                            \n",
    "                            # Add tool-generated images as additional content\n",
    "                            for image in tool_images:\n",
    "                                # Convert tool image format to Claude response format\n",
    "                                image_block = type('ImageBlock', (), {\n",
    "                                    'type': 'image',\n",
    "                                    'source': type('Source', (), {\n",
    "                                        'data': image['source']['data'],\n",
    "                                        'media_type': image['source']['media_type']\n",
    "                                    })()\n",
    "                                })()\n",
    "                                self.content.append(image_block)\n",
    "                    \n",
    "                    # Return enhanced response with images\n",
    "                    return ResponseWithImages(response, tool_images)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in iteration {iteration + 1}: {e}\")\n",
    "                return None\n",
    "        \n",
    "        print(f\"\\nReached maximum iterations ({max_iterations})\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a72c0",
   "metadata": {},
   "source": [
    "Next we'll define an MCP tool for comparing annual weather statistics at one or more locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_locations_mcp(\n",
    "    locations: list,\n",
    "    variable: str,\n",
    "    threshold_min: float = None,\n",
    "    threshold_max: float = None,\n",
    "    start_year: int = None,\n",
    "    end_year: int = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Compare the annual weather statistics for one or more locations.\n",
    "    \n",
    "    Args:\n",
    "        locations: List of locations to analyze and compare\n",
    "        variable: Weather variable to compare\n",
    "        threshold_min: Optional minimum threshold (inclusive)\n",
    "        threshold_max: Optional maximum threshold (inclusive)\n",
    "        start_year: Start year (default: 50 years before end_year)\n",
    "        end_year: End year (default: previous year)\n",
    "        \n",
    "    Returns:\n",
    "        JSON string containing weather comparison text and chart data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not locations or len(locations) == 0:\n",
    "            return json.dumps({\"error\": \"At least one location must be provided\"})\n",
    "        \n",
    "        # Convert dictionaries to Location objects\n",
    "        location_objects = []\n",
    "        for loc in locations:\n",
    "            if isinstance(loc, dict):\n",
    "                location_objects.append(Location(\n",
    "                    name=loc[\"name\"],\n",
    "                    latitude=loc[\"latitude\"],\n",
    "                    longitude=loc[\"longitude\"]\n",
    "                ))\n",
    "            else:\n",
    "                location_objects.append(loc)\n",
    "\n",
    "        # Set default year range if not provided\n",
    "        if end_year is None:\n",
    "            end_year = datetime.now().year - 1  # Default to previous year\n",
    "        if start_year is None:\n",
    "            start_year = end_year - 50  # Default to 50 years before end_year\n",
    "        \n",
    "        # Fetch weather data for all locations\n",
    "        weather_data = get_weather_data(\n",
    "            locations=location_objects,\n",
    "            start_date=f\"{start_year}-01-01\",\n",
    "            end_date=f\"{end_year}-12-31\",\n",
    "            variables=[variable]\n",
    "        )\n",
    "                \n",
    "        # Calculate annual statistics if thresholds were provided\n",
    "        if threshold_min is not None or threshold_max is not None:\n",
    "            annual_stats = calculate_annual_stats(\n",
    "                daily_data=weather_data,\n",
    "                variable=variable,\n",
    "                threshold_min=threshold_min,\n",
    "                threshold_max=threshold_max\n",
    "            )\n",
    "            \n",
    "            # Create chart\n",
    "            threshold_desc = \"\"\n",
    "            if threshold_min is not None and threshold_max is not None:\n",
    "                threshold_desc = f\"Days of {variable} between {threshold_min} and {threshold_max}\"\n",
    "            elif threshold_min is not None:\n",
    "                threshold_desc = f\"Days of {variable} above {threshold_min}\"\n",
    "            elif threshold_max is not None:\n",
    "                threshold_desc = f\"Days of {variable} below {threshold_max}\"\n",
    "            \n",
    "            chart = create_annual_stats_chart(annual_stats, threshold_desc)\n",
    "        else:\n",
    "            # Just show raw data comparison without thresholds\n",
    "            annual_stats = None\n",
    "            chart = None\n",
    "        \n",
    "        # Generate comparison text for all locations\n",
    "        comparison_text = f\"🌍 Location Analysis: {', '.join([loc.name for loc in location_objects])}\\n\\n\"\n",
    "        comparison_text += f\"📊 {variable.replace('_', ' ').title()} Analysis:\\n\\n\"\n",
    "        \n",
    "        # Statistics for each location\n",
    "        location_stats = []\n",
    "        for loc in location_objects:\n",
    "            loc_data = weather_data[weather_data['location_name'] == loc.name]\n",
    "            if not loc_data.empty:\n",
    "                avg_val = loc_data[variable].mean()\n",
    "                min_val = loc_data[variable].min()\n",
    "                max_val = loc_data[variable].max()\n",
    "                \n",
    "                location_stats.append({\n",
    "                    'name': loc.name,\n",
    "                    'avg': avg_val,\n",
    "                    'min': min_val,\n",
    "                    'max': max_val,\n",
    "                    'coordinates': f\"{loc.latitude}, {loc.longitude}\"\n",
    "                })\n",
    "                \n",
    "                comparison_text += f\"🏙️ **{loc.name}**\\n\"\n",
    "                comparison_text += f\"• Average: {avg_val:.1f}\\n\"\n",
    "                comparison_text += f\"• Range: {min_val:.1f} to {max_val:.1f}\\n\" \n",
    "                comparison_text += f\"• Coordinates: {loc.latitude}, {loc.longitude}\\n\\n\"\n",
    "\n",
    "        # Add threshold-based analysis if applicable\n",
    "        if annual_stats is not None:\n",
    "            comparison_text += \"🎯 **Threshold Analysis:**\\n\"\n",
    "            \n",
    "            # Calculate average days per location\n",
    "            for loc in location_objects:\n",
    "                loc_stats = annual_stats[annual_stats['location_name'] == loc.name]\n",
    "                if not loc_stats.empty:\n",
    "                    avg_days = loc_stats['count'].mean()\n",
    "                    comparison_text += f\"• {loc.name}: {avg_days:.0f} days per year on average\\n\"\n",
    "            \n",
    "            comparison_text += f\"• Criteria: {threshold_desc}\\n\\n\"\n",
    "        \n",
    "        # Add summary comparison if more than one location\n",
    "        if len(location_objects) > 1:\n",
    "            comparison_text += \"🏆 **Summary:**\\n\"\n",
    "            \n",
    "            # Find best and worst for average values\n",
    "            if location_stats:\n",
    "                best_avg = max(location_stats, key=lambda x: x['avg'])\n",
    "                worst_avg = min(location_stats, key=lambda x: x['avg'])\n",
    "                \n",
    "                comparison_text += f\"• Highest average {variable.replace('_', ' ')}: {best_avg['name']} ({best_avg['avg']:.1f})\\n\"\n",
    "                comparison_text += f\"• Lowest average {variable.replace('_', ' ')}: {worst_avg['name']} ({worst_avg['avg']:.1f})\\n\"\n",
    "                \n",
    "                # Add threshold analysis summary if available\n",
    "                if annual_stats is not None:\n",
    "                    threshold_stats = []\n",
    "                    for loc in location_objects:\n",
    "                        loc_stats = annual_stats[annual_stats['location_name'] == loc.name]\n",
    "                        if not loc_stats.empty:\n",
    "                            avg_days = loc_stats['count'].mean()\n",
    "                            threshold_stats.append({'name': loc.name, 'avg_days': avg_days})\n",
    "                    \n",
    "                    if threshold_stats:\n",
    "                        best_threshold = max(threshold_stats, key=lambda x: x['avg_days'])\n",
    "                        comparison_text += f\"• Most days meeting criteria: {best_threshold['name']} ({best_threshold['avg_days']:.0f} days/year)\\n\"\n",
    "\n",
    "        result = {\"text\": comparison_text}\n",
    "        if chart:\n",
    "            result[\"chart_json\"] = chart.to_dict()\n",
    "            \n",
    "        return json.dumps(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Location analysis failed: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f3aa2",
   "metadata": {},
   "source": [
    "## 🧪 **Try It Out**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91c32b",
   "metadata": {},
   "source": [
    "Start by creating an instance of the MCP client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client = MCPClient(get_api_key())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d8d8a",
   "metadata": {},
   "source": [
    "Next, register our tool with the MCP client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b72ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client.register_tool(\n",
    "    name=\"compare_locations_mcp\",\n",
    "    description=\"Analyze and compare annual weather statistics for one or more cities with optional threshold analysis and visualization.\",\n",
    "    input_schema={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"locations\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"List of locations to analyze and compare\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"latitude\": {\"type\": \"number\"},\n",
    "                            \"longitude\": {\"type\": \"number\"}\n",
    "                        },\n",
    "                        \"required\": [\"name\", \"latitude\", \"longitude\"]\n",
    "                    },\n",
    "                    \"minItems\": 1\n",
    "                },\n",
    "                \"variable\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Weather variable to compare\",\n",
    "                    \"enum\": weather_variables,\n",
    "                },\n",
    "                \"threshold_min\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Optional minimum threshold for counting days (inclusive)\"\n",
    "                },\n",
    "                \"threshold_max\": {\n",
    "                    \"type\": \"number\", \n",
    "                    \"description\": \"Optional maximum threshold for counting days (inclusive)\"\n",
    "                },\n",
    "                \"start_year\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Start year (default: 50 years before end_year)\"\n",
    "                },\n",
    "                \"end_year\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"End year (default: previous year)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"locations\"]\n",
    "        },\n",
    "    function=compare_locations_mcp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e559d",
   "metadata": {},
   "source": [
    "We can verify that the MCP tool is configured properly, by executing the tool directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_results_str = mcp_client.execute_tool(\n",
    "  tool_name=\"compare_locations_mcp\",\n",
    "  tool_input={\n",
    "    \"locations\": [\n",
    "        {\n",
    "            \"name\": \"San Francisco\",\n",
    "            \"latitude\": 37.7749,\n",
    "            \"longitude\": -122.4194\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Seattle\",\n",
    "            \"latitude\": 47.6062,\n",
    "            \"longitude\": -122.3321\n",
    "        }\n",
    "    ],\n",
    "    \"variable\": \"temperature_2m_max\",\n",
    "    \"threshold_min\": 18,\n",
    "    \"threshold_max\": 24,\n",
    "    \"start_year\": 2000,\n",
    "    \"end_year\": 2019\n",
    "})\n",
    "\n",
    "tool_results = json.loads(tool_results_str)\n",
    "\n",
    "# Display the tool results\n",
    "display(Markdown(tool_results['text']))\n",
    "if 'chart_json' in tool_results:\n",
    "  display(alt.Chart.from_dict(tool_results['chart_json']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc5944",
   "metadata": {},
   "source": [
    "## Display Helper Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c297ccc",
   "metadata": {},
   "source": [
    "We need one final utility function to properly display Claude's responses in our notebook. This function handles both text content and interactive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0642b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_claude_response(response):\n",
    "    \"\"\"Display Claude response with both text and images\"\"\"    \n",
    "    if response:\n",
    "        for content in response.content:\n",
    "            if content.type == \"text\":\n",
    "                display(Markdown(content.text))\n",
    "            elif content.type == \"image\":\n",
    "                if content.source.media_type == \"application/vnd.vegalite.v5+json\":\n",
    "                    # Recreate the chart from JSON dictionary\n",
    "                    altair_chart = alt.Chart.from_dict(content.source.data)\n",
    "                    display(altair_chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0aca21",
   "metadata": {},
   "source": [
    "# MCP in Action: Querying with Enhanced Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0827776",
   "metadata": {},
   "source": [
    "Now for the exciting part! Let's see how Claude performs with our MCP tools compared to its earlier limitations.\n",
    "\n",
    "### Revisiting Our Weather Question\n",
    "\n",
    "First, let's review the complex weather question we asked earlier (without tools):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987676de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e24f60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Tip:</b> Update this question ask for locations that are relevant to you!<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce350ea6",
   "metadata": {},
   "source": [
    "Now let's ask Claude the same question, this time using the MCP tool we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mcp_client.chat_with_tools(weather_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aab7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_claude_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b25830",
   "metadata": {},
   "source": [
    "### 🎉 **The Transformation**\n",
    "\n",
    "Notice the dramatic difference! With MCP integration, Claude now provides:\n",
    "- **Specific numerical data** from real weather records\n",
    "- **Custom analysis** tailored to your exact criteria  \n",
    "- **Interactive visualizations** generated from actual datasets\n",
    "- **Data-driven insights** impossible without external data access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6111a",
   "metadata": {},
   "source": [
    "# 🚀 Where to Next?\n",
    "\n",
    "You now have a powerful foundation for connecting AI to external data sources. Here are some exciting directions to explore:\n",
    "\n",
    "## Expand Weather Analysis\n",
    "- Implement additional [ETCCDI Climate Change Indices](https://etccdi.pacificclimate.org/list_27_indices.shtml) compiled by [CLIVAR](https://www.clivar.org/)\n",
    "- Add weather forecast analysis using the [Open-Meteo Forecast API](https://open-meteo.com/en/docs) (16-day forecasts instead of historical data)\n",
    "\n",
    "## Apply to Other Domains  \n",
    "- **Genomics**: Connect to sequence databases like the [Sequence Read Archive](https://www.ncbi.nlm.nih.gov/sra/docs/)\n",
    "- **Geospatial**: Integrate satellite imagery from [Landsat Collection 2](https://www.usgs.gov/landsat-missions/landsat-commercial-cloud-data-access)\n",
    "- **Business**: Link to sales data, market research, or customer analytics APIs\n",
    "- **Finance**: Access real-time market data, economic indicators, or trading APIs\n",
    "- **Healthcare**: Query medical databases, research papers, or treatment outcome datasets\n",
    "\n",
    "## Technical Enhancements\n",
    "- Build standalone MCP servers that other clients can use\n",
    "- Add authentication and rate limiting for production use\n",
    "- Implement data caching and optimization strategies\n",
    "- Create interactive web interfaces for non-technical users\n",
    "\n",
    "The MCP patterns you've learned here will work with any external data source. The possibilities are truly limitless! ✨\n",
    "\n",
    "**Happy data exploring!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
