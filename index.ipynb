{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7752c7",
   "metadata": {},
   "source": [
    "# MCP Historical Weather Comparison\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use **Model Context Protocol (MCP)** to extend Claude's capabilities with real-time data access. We'll build a system that allows Claude to access historical weather data and compare annual weather statistics between two locations.\n",
    "\n",
    "### What is MCP?\n",
    "\n",
    "Model Context Protocol (MCP) is a standard that enables AI models to securely connect with external data sources and tools. Instead of being limited to training data, models can access live information, APIs, and services.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Limitations of LLMs without external tools** - See how Claude responds to weather queries without access to real data\n",
    "2. **MCP Integration** - Connect Claude to a historical weather API\n",
    "3. **Data Visualization** - Create aesthetically pleasing charts comparing weather patterns\n",
    "4. **Interactive Analysis** - Ask Claude to analyze and compare weather data between locations\n",
    "\n",
    "### Goals\n",
    "\n",
    "By the end of this notebook, you'll have a working system that can:\n",
    "- Fetch historical weather data for any location\n",
    "- Compare annual weather statistics between two cities\n",
    "- Generate visualizations and insights about weather patterns\n",
    "- Demonstrate the power of extending LLMs with external data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfc692",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "This notebook is designed to work in both Google Colab and local Jupyter environments. The following cell will automatically detect the environment and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "s0296q9lew9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Install required packages\n",
    "if IN_COLAB:\n",
    "    # Install packages for Colab environment\n",
    "    packages = [\n",
    "        \"anthropic>=0.66.0\",\n",
    "        \"altair>=5.5.0\",\n",
    "        \"openmeteo-requests>=1.7.2\"\n",
    "        \"pandas>=2.3.2\",\n",
    "        \"requests>=2.32.5\",\n",
    "        \"retry-requests>=2.0.0\",\n",
    "        \"requests-cache==1.2.1\",\n",
    "    ]\n",
    "    !pip install {\" \".join(packages)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i7eh8nmjwt",
   "metadata": {},
   "source": [
    "### Python Package Imports\n",
    "\n",
    "Now let's import all the necessary packages for our weather comparison system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shi699mdg4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from typing import Optional, Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data handling and validation\n",
    "import requests\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# Visualization\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "# For displaying rich notebook content\n",
    "from IPython.display import Image, Markdown, display\n",
    "\n",
    "# Claude API\n",
    "from anthropic import Anthropic\n",
    "\n",
    "import requests_cache  # for caching API responses\n",
    "from retry_requests import retry  # for retrying API requests\n",
    "import openmeteo_requests  # for making API requests to Open-Meteo\n",
    "\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tvr3i79qmng",
   "metadata": {},
   "source": [
    "### Anthropic API Key Setup\n",
    "\n",
    "We need to securely obtain your Anthropic API key to interact with Claude. This function will try multiple methods in order of preference for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "r9yh2vsfxv9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    try:\n",
    "        if IN_COLAB:\n",
    "            # Import package for accessing user data\n",
    "            from google.colab import userdata\n",
    "            api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "        else:\n",
    "            api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    except:\n",
    "        # Prompt user for their API key\n",
    "        api_key = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575uf18qwy",
   "metadata": {},
   "source": [
    "## Motivation: Do we actually need to extend LLMs?\n",
    "\n",
    "Before diving into MCP integration, let's first see what happens when we ask Claude to compare weather data between two locations **without giving it access to any external tools or data sources**.\n",
    "\n",
    "This will demonstrate the fundamental limitation of LLMs: they can only work with information from their training data, which has a knowledge cutoff and may not include specific, current, or detailed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "w7cevzhn4cr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Asking Claude about weather data WITHOUT external tools...\n",
      "======================================================================\n",
      "Question: \n",
      "Please compare the annual weather statistics for San Francisco, California\n",
      "and Redwood City, California for the years 2000-2023. \n",
      "I'd like to see:\n",
      "\n",
      "1. Average temperatures by year\n",
      "2. Total precipitation by year  \n",
      "3. Number of sunny days by year\n",
      "4. Humidity levels by year\n",
      "5. Any notable weather patterns or extremes\n",
      "\n",
      "Please provide specific data and create a comparison showing which city had more favorable weather conditions.\n",
      "\n",
      "======================================================================\n",
      "Claude's Response:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I don't have access to the specific detailed weather database you're requesting for San Francisco and Redwood City from 2000-2023. However, I can provide you with general climate characteristics and guide you to the best sources for this data.\n",
       "\n",
       "## General Climate Comparison\n",
       "\n",
       "**San Francisco:**\n",
       "- Maritime Mediterranean climate\n",
       "- Average annual temperature: 57-59Â°F\n",
       "- Annual precipitation: ~23-24 inches\n",
       "- Frequent fog, especially summer mornings\n",
       "- Less temperature variation due to ocean influence\n",
       "\n",
       "**Redwood City:**\n",
       "- Mediterranean climate with more continental influence\n",
       "- Average annual temperature: 58-61Â°F\n",
       "- Annual precipitation: ~20-22 inches\n",
       "- Less fog, more sunshine\n",
       "- Greater temperature variation than SF\n",
       "\n",
       "## Best Data Sources\n",
       "\n",
       "For the specific annual statistics you need (2000-2023), I recommend:\n",
       "\n",
       "1. **National Weather Service** - weather.gov\n",
       "2. **NOAA Climate Data Online** - ncdc.noaa.gov\n",
       "3. **Weather Underground Historical** - wunderground.com/history\n",
       "4. **California Climate Tracker** - cal-adapt.org\n",
       "5. **Bay Area Air Quality Management District** (for additional climate data)\n",
       "\n",
       "## What You'll Typically Find\n",
       "\n",
       "**More Favorable in Redwood City:**\n",
       "- More sunny days annually\n",
       "- Less fog interference\n",
       "- Warmer summer temperatures\n",
       "- Lower humidity levels\n",
       "\n",
       "**More Favorable in San Francisco:**\n",
       "- More stable temperatures year-round\n",
       "- Natural air conditioning from ocean\n",
       "- Less extreme heat events\n",
       "\n",
       "Would you like me to help you navigate any of these data sources, or would you prefer guidance on how to analyze the data once you obtain it?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_claude_without_tools(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to Claude without any external tools or data access.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask Claude\n",
    "    \n",
    "    Returns:\n",
    "        Claude's response as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = Anthropic(api_key=get_api_key())\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": question\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test Claude's response without external data\n",
    "weather_question = \"\"\"\n",
    "Please compare the annual weather statistics for San Francisco, California\n",
    "and Redwood City, California for the years 2000-2023. \n",
    "I'd like to see:\n",
    "\n",
    "1. Average temperatures by year\n",
    "2. Total precipitation by year  \n",
    "3. Number of sunny days by year\n",
    "4. Humidity levels by year\n",
    "5. Any notable weather patterns or extremes\n",
    "\n",
    "Please provide specific data and create a comparison showing which city had more favorable weather conditions.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸ¤– Asking Claude about weather data WITHOUT external tools...\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Question: {weather_question}\")\n",
    "print(\"=\"*70)\n",
    "print(\"Claude's Response:\")\n",
    "print()\n",
    "\n",
    "response = ask_claude_without_tools(weather_question)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51k0jp8n6wb",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "As you can see from Claude's response above, without access to external data sources, the model has several limitations:\n",
    "\n",
    "1. **No real-time data**: Claude can't access current or specific historical weather data\n",
    "2. **General knowledge only**: Responses are based on general patterns from training data\n",
    "3. **No specific metrics**: Can't provide exact precipitation amounts, temperatures, or day counts\n",
    "4. **No visualizations**: Can't create charts or graphs from actual data\n",
    "\n",
    "This demonstrates why **Model Context Protocol (MCP)** is valuable - it bridges the gap between the model's reasoning capabilities and real-world data access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zkk6m7ulbb",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "*This section will contain analysis of weather data patterns and comparisons between locations once we implement the MCP integration.*\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Weather API] --> B[MCP Server]\n",
    "    B --> C[Claude Client]\n",
    "    C --> D[Data Analysis]\n",
    "    D --> E[Visualization]\n",
    "    E --> F[User Insights]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b013d",
   "metadata": {},
   "source": [
    "In this section we will create some Python functions that:\n",
    "- retrieve daily data from the Open-Mateo Weather API for a list of locations\n",
    "- aggregate daily data to annual summaries\n",
    "- create a time-series chart, plotting the annual data and a trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f95994",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(BaseModel):\n",
    "    name: str\n",
    "    longitude: float\n",
    "    latitude: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cde5c4",
   "metadata": {},
   "source": [
    "## Get weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "weather_variables = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_mean\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"rain_sum\",\n",
    "    \"snowfall_sum\",\n",
    "    \"precipitation_hours\",\n",
    "    \"sunshine_duration\"\n",
    "  ]\n",
    "\n",
    "# Setup an Open-Meteo API client with a cache and retry mechanism\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b881f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(\n",
    "      locations: list[Location],\n",
    "      start_date: str,\n",
    "      end_date: str,\n",
    "      variables: list[str]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Get weather data for one or more locations.\n",
    "    \n",
    "    Args:\n",
    "        locations: List of Location objects\n",
    "        start_date: Start date in YYYY-MM-DD format\n",
    "        end_date: End date in YYYY-MM-DD format\n",
    "        variables: List of weather variables to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame with weather data\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_response(variables, response, location_name):\n",
    "        daily = response.Daily()\n",
    "        daily_data_dict = {\n",
    "            \"date\": pd.date_range(\n",
    "            start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "            inclusive = \"left\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # Add the variable data.\n",
    "        for i, variable in enumerate(variables):\n",
    "            daily_data_dict[variable] = daily.Variables(i).ValuesAsNumpy()\n",
    "\n",
    "        # Add a column for the location name.\n",
    "        daily_data_dict[\"location_name\"] = location_name\n",
    "\n",
    "        return pd.DataFrame(daily_data_dict)\n",
    "\n",
    "  \n",
    "    params = {\n",
    "        \"latitude\": [x.latitude for x in locations],\n",
    "        \"longitude\": [x.longitude for x in locations],\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": variables,\n",
    "    }\n",
    "\n",
    "    # Query for weather data and get one response per location.\n",
    "    responses = openmeteo.weather_api(api_url, params=params)\n",
    "\n",
    "    # Concatenate all of the responses into a single dataframe\n",
    "    daily_df_list = [parse_response(variables, response, locations[i].name) for i, response in enumerate(responses)]\n",
    "    daily_df = pd.concat(daily_df_list, axis=0)\n",
    "\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584e642",
   "metadata": {},
   "source": [
    "### Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af3754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00+00:00</td>\n",
       "      <td>7.517750</td>\n",
       "      <td>11.574000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29323.564453</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02 00:00:00+00:00</td>\n",
       "      <td>8.274000</td>\n",
       "      <td>12.074000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30698.628906</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 00:00:00+00:00</td>\n",
       "      <td>7.753168</td>\n",
       "      <td>12.524000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30748.666016</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04 00:00:00+00:00</td>\n",
       "      <td>8.513582</td>\n",
       "      <td>11.974000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7515.774902</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05 00:00:00+00:00</td>\n",
       "      <td>10.132333</td>\n",
       "      <td>15.374000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25200.000000</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>2019-12-27 00:00:00+00:00</td>\n",
       "      <td>9.072333</td>\n",
       "      <td>12.764000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30670.558594</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>2019-12-28 00:00:00+00:00</td>\n",
       "      <td>8.845249</td>\n",
       "      <td>13.113999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30593.238281</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2019-12-29 00:00:00+00:00</td>\n",
       "      <td>9.170250</td>\n",
       "      <td>13.814000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>19493.875000</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>2019-12-30 00:00:00+00:00</td>\n",
       "      <td>9.747333</td>\n",
       "      <td>13.814000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>25299.003906</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>2019-12-31 00:00:00+00:00</td>\n",
       "      <td>9.872333</td>\n",
       "      <td>14.863999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30771.066406</td>\n",
       "      <td>San Jose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21915 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  temperature_2m_mean  temperature_2m_max  \\\n",
       "0    2000-01-01 00:00:00+00:00             7.517750           11.574000   \n",
       "1    2000-01-02 00:00:00+00:00             8.274000           12.074000   \n",
       "2    2000-01-03 00:00:00+00:00             7.753168           12.524000   \n",
       "3    2000-01-04 00:00:00+00:00             8.513582           11.974000   \n",
       "4    2000-01-05 00:00:00+00:00            10.132333           15.374000   \n",
       "...                        ...                  ...                 ...   \n",
       "7300 2019-12-27 00:00:00+00:00             9.072333           12.764000   \n",
       "7301 2019-12-28 00:00:00+00:00             8.845249           13.113999   \n",
       "7302 2019-12-29 00:00:00+00:00             9.170250           13.814000   \n",
       "7303 2019-12-30 00:00:00+00:00             9.747333           13.814000   \n",
       "7304 2019-12-31 00:00:00+00:00             9.872333           14.863999   \n",
       "\n",
       "      rain_sum  sunshine_duration  location_name  \n",
       "0          0.0       29323.564453  San Francisco  \n",
       "1          0.0       30698.628906  San Francisco  \n",
       "2          0.0       30748.666016  San Francisco  \n",
       "3          0.6        7515.774902  San Francisco  \n",
       "4          0.0       25200.000000  San Francisco  \n",
       "...        ...                ...            ...  \n",
       "7300       0.0       30670.558594       San Jose  \n",
       "7301       0.0       30593.238281       San Jose  \n",
       "7302       1.3       19493.875000       San Jose  \n",
       "7303       5.7       25299.003906       San Jose  \n",
       "7304       0.0       30771.066406       San Jose  \n",
       "\n",
       "[21915 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_locations = [\n",
    "  Location(\n",
    "    name='San Francisco',\n",
    "    latitude=37.7749,\n",
    "    longitude=-122.4194,\n",
    "  ),\n",
    "  Location(\n",
    "    name='Redwood City',\n",
    "    latitude=37.4848,\n",
    "    longitude=-122.2281,\n",
    "  ),\n",
    "  Location(\n",
    "    name='San Jose',\n",
    "    latitude=37.3382,\n",
    "    longitude=-121.8863,\n",
    "  )\n",
    "]\n",
    "\n",
    "# Test the original functionality\n",
    "daily_data = get_weather_data(\n",
    "  locations=test_locations,\n",
    "  start_date=\"2000-01-01\",\n",
    "  end_date=\"2019-12-31\",\n",
    "  variables=['temperature_2m_mean', 'temperature_2m_max', 'rain_sum', 'sunshine_duration']\n",
    ")\n",
    "daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19105086",
   "metadata": {},
   "source": [
    "## Calculate Annual Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392a73a",
   "metadata": {},
   "source": [
    "To enable better long-term comparisons, we can write a function that calculates annual statistics of how many times a variable exceeds a minimum or maximum threshold.\n",
    "\n",
    "Examples:\n",
    "- Days that the maximum temperature exceeds 30 degrees C\n",
    "- Days that the mean temperatures is between 20 and 25 degrees C\n",
    "- Days that rain exceeds 2 mm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29650c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_annual_stats(\n",
    "    daily_data: pd.DataFrame,\n",
    "    variable: str,\n",
    "    threshold_min: float = None,\n",
    "    threshold_max: float = None\n",
    "    ) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Calculate annual statistics for the given daily data.\n",
    "  \n",
    "  Args:\n",
    "    daily_data: DataFrame containing weather data\n",
    "    variable: Name of the variable column to analyze\n",
    "    threshold_min: Optional minimum threshold (inclusive)\n",
    "    threshold_max: Optional maximum threshold (inclusive)\n",
    "  \n",
    "  Returns:\n",
    "    DataFrame with columns: year, count, location_name\n",
    "  \"\"\"\n",
    "  # Validate threshold parameters\n",
    "  if threshold_min is None and threshold_max is None:\n",
    "    raise ValueError(\"At least one of threshold_min or threshold_max must be provided\")\n",
    "  \n",
    "  # Get unique location names from the daily data\n",
    "  locations = daily_data['location_name'].unique()\n",
    "  \n",
    "  # Initialize list to store results\n",
    "  results = []\n",
    "  \n",
    "  # Process each location\n",
    "  for location in locations:\n",
    "    # Filter data for this location and make an explicit copy to avoid SettingWithCopyWarning\n",
    "    location_data = daily_data[daily_data['location_name'] == location].copy()\n",
    "    \n",
    "    # Extract year from date column\n",
    "    location_data['year'] = pd.to_datetime(location_data['date']).dt.year\n",
    "    \n",
    "    # Apply threshold filters\n",
    "    def count_days_in_range(x):\n",
    "      mask = pd.Series(True, index=x.index)  # Start with all True\n",
    "      \n",
    "      if threshold_min is not None:\n",
    "        mask = mask & (x >= threshold_min)\n",
    "      \n",
    "      if threshold_max is not None:\n",
    "        mask = mask & (x <= threshold_max)\n",
    "      \n",
    "      return mask.sum()\n",
    "    \n",
    "    yearly_counts = location_data.groupby('year')[variable].apply(count_days_in_range)\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    yearly_df = pd.DataFrame({\n",
    "      'year': yearly_counts.index,\n",
    "      'count': yearly_counts.values,\n",
    "      'location_name': location\n",
    "    })\n",
    "    \n",
    "    results.append(yearly_df)\n",
    "    \n",
    "  # Combine all results\n",
    "  return pd.concat(results, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce3e12f",
   "metadata": {},
   "source": [
    "### Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88416359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>88</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>101</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>86</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>106</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>112</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  count  location_name\n",
       "0  2000     88  San Francisco\n",
       "1  2001    101  San Francisco\n",
       "2  2002     86  San Francisco\n",
       "3  2003    106  San Francisco\n",
       "4  2004    112  San Francisco"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_stats = calculate_annual_stats(\n",
    "    daily_data,\n",
    "    variable='temperature_2m_max',\n",
    "    threshold_min=20,\n",
    "    threshold_max=25\n",
    ")\n",
    "annual_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829f962",
   "metadata": {},
   "source": [
    "## Create a Timeseries Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393761b",
   "metadata": {},
   "source": [
    "Even tables of annual statistics can get pretty long, so we create a function for charting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4344a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annual_stats_chart(\n",
    "    annual_stats: pd.DataFrame,\n",
    "    title: str\n",
    "  ) -> alt.Chart:\n",
    "  \"\"\"\n",
    "  Create a chart showing the annual statistics.\n",
    "  \"\"\"\n",
    "  # Base chart with data points\n",
    "  base = alt.Chart(annual_stats).encode(\n",
    "    x='year:O',\n",
    "    y='count:Q',\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Create line chart\n",
    "  lines = base.mark_line()\n",
    "\n",
    "  # Add trend lines\n",
    "  trend_lines = base.transform_regression(\n",
    "    'year', 'count', \n",
    "    groupby=['location_name']\n",
    "  ).mark_line(\n",
    "    strokeDash=[5,5]\n",
    "  ).encode(\n",
    "    color='location_name:N'\n",
    "  )\n",
    "\n",
    "  # Combine the line and trend lines\n",
    "  return (lines + trend_lines).properties(\n",
    "    title=title\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165d51f",
   "metadata": {},
   "source": [
    "### Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e8aa1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45.vega-embed details,\n",
       "  #altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8b42c02d4ecb4ba1b01c92eb89306e45\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"location_name\", \"type\": \"nominal\"}, \"x\": {\"field\": \"year\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"count\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"line\", \"strokeDash\": [5, 5]}, \"encoding\": {\"color\": {\"field\": \"location_name\", \"type\": \"nominal\"}, \"x\": {\"field\": \"year\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"count\", \"type\": \"quantitative\"}}, \"transform\": [{\"on\": \"year\", \"regression\": \"count\", \"groupby\": [\"location_name\"]}]}], \"data\": {\"url\": \"altair-data-22fd4745e8303b1b7a1ba6aee30f434c.json\", \"format\": {\"type\": \"json\"}}, \"title\": \"Days with Temperature Mean between 20 and 25 degrees C\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_annual_stats_chart(\n",
    "    annual_stats,\n",
    "    title='Days with Temperature Mean between 20 and 25 degrees C'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb71e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
